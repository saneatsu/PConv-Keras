{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Training\n",
    "Having implemented and tested all the components of the final networks in steps 1-3, we are now ready to train the network on a large dataset (ImageNet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/Pconv-Keras/lib/python3.6/site-packages/matplotlib/__init__.py:995: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/Pconv-Keras/lib/python3.6/site-packages/matplotlib/__init__.py:995: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import gc\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras import backend as K\n",
    "\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import NullFormatter\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "import const as cst\n",
    "from libs.pconv_model import PConvUnet\n",
    "from libs.util import random_mask\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating train & test data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(ImageDataGenerator):\n",
    "    def flow_from_directory(self, directory, *args, **kwargs):\n",
    "        generator = super().flow_from_directory(directory, class_mode=None, *args, **kwargs)\n",
    "        while True:\n",
    "            \n",
    "            # Get augmented image samples\n",
    "            ori = next(generator)\n",
    "\n",
    "            # Get masks for each image sample\n",
    "            mask = np.stack([random_mask(ori.shape[1], ori.shape[2]) for _ in range(ori.shape[0])], axis=0)\n",
    "\n",
    "            # Apply masks to all image sample\n",
    "            masked = deepcopy(ori)\n",
    "            masked[mask==0] = 1\n",
    "            \n",
    "            print(ori.shape)\n",
    "            print(mask.shape)\n",
    "            \n",
    "\n",
    "            # Yield ([ori, masl],  ori) training batches\n",
    "            # print(masked.shape, ori.shape)\n",
    "            gc.collect()\n",
    "            yield [masked, mask], ori\n",
    "\n",
    "            \n",
    "# # Create training generator\n",
    "# train_datagen = DataGenerator(  \n",
    "#     rotation_range=20,\n",
    "#     width_shift_range=0.2,\n",
    "#     height_shift_range=0.2,\n",
    "#     rescale=1./255,\n",
    "#     horizontal_flip=True\n",
    "# )\n",
    "# train_generator = train_datagen.flow_from_directory(\n",
    "#     cst.TRAIN_PATH, target_size=(256, 512), batch_size=BATCH_SIZE\n",
    "# )\n",
    "\n",
    "# # # Create validation generator\n",
    "# val_datagen = DataGenerator(rescale=1./255)\n",
    "# val_generator = val_datagen.flow_from_directory(\n",
    "#     cst.VAL_PATH, target_size=(256, 512), batch_size=BATCH_SIZE, seed=1\n",
    "# )\n",
    "\n",
    "# Create testing generator\n",
    "test_datagen = DataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    cst.TEST_PATH,\n",
    "    target_size=(cst.MAX_HEIGHT, cst.MAX_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=1\n",
    ")\n",
    "\n",
    "# cst.MAX_HEIGHT, cst.MAX_WIDTH\n",
    "\n",
    "# test_datagen = DataGenerator(\n",
    "#                     rescale=1./255,\n",
    "#                     random_crop_size=(cst.CROP_HEIGHT, cst.CROP_WIDTH))\n",
    "# test_generator = test_datagen.flow_from_directory(\n",
    "#                     cst.TEST_PATH,\n",
    "#                     target_size=(cst.CROP_HEIGHT, cst.CROP_WIDTH),\n",
    "#                     batch_size=BATCH_SIZE,\n",
    "#                     seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 images belonging to 1 classes.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "empty range for randrange() (3,2, -1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-638825d3ed00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Pick out an example\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmasked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mori\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Show side by side\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-04d9044410b7>\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, *args, **kwargs)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0;31m# Get masks for each image sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrandom_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mori\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mori\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mori\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;31m# Apply masks to all image sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-04d9044410b7>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0;31m# Get masks for each image sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrandom_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mori\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mori\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mori\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;31m# Apply masks to all image sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/PConv-Keras/libs/util.py\u001b[0m in \u001b[0;36mrandom_mask\u001b[0;34m(height, width, channels)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mthickness\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthickness\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Pconv-Keras/lib/python3.6/random.py\u001b[0m in \u001b[0;36mrandint\u001b[0;34m(self, a, b)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \"\"\"\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     def _randbelow(self, n, int=int, maxsize=1<<BPF, type=type,\n",
      "\u001b[0;32m~/anaconda3/envs/Pconv-Keras/lib/python3.6/random.py\u001b[0m in \u001b[0;36mrandrange\u001b[0;34m(self, start, stop, step, _int)\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mistart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_randbelow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"empty range for randrange() (%d,%d, %d)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mistart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mistop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;31m# Non-unit step argument supplied.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: empty range for randrange() (3,2, -1)"
     ]
    }
   ],
   "source": [
    "# Pick out an example\n",
    "test_data = next(test_generator)\n",
    "(masked, mask), ori = test_data\n",
    "\n",
    "# Show side by side\n",
    "for i in range(len(ori)):\n",
    "    _, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "    axes[0].imshow(masked[i,:,:,:])\n",
    "    axes[1].imshow(mask[i,:,:,:] * 1.)\n",
    "    axes[2].imshow(ori[i,:,:,:])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check 'nan' in weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from libs.pconv_model import PConvUnet\n",
    "# from keras.layers.wrappers import Wrapper\n",
    "# from keras.layers import Dense, Dropout, Flatten, Input\n",
    "# from keras.models import Model\n",
    "\n",
    "# print(model.layers)\n",
    "# print(type(model.layers))\n",
    "\n",
    "# for layer in model.layers:\n",
    "#     weights = layer.get_weights()\n",
    "#     for weight in weights:\n",
    "#         print(weight.shape)\n",
    "#         if np.any(np.isnan(weight)):\n",
    "#             print(layer.name)\n",
    "#             print(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create mask using weight made by multi GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PConvUnet(weight_filepath='data/logs/')\n",
    "model.load(\n",
    "    '/mnt/PConv-Keras/data/model/weight-resize-1536x3072/weight-crop-512x512v2/20_weights_2018-11-07-14-33-30.h5',\n",
    "    train_bn=False,\n",
    "    lr=0.00005\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Masked, Predicted, Originalの画像をそれぞれ保存 by using PIL\n",
    "from PIL import Image\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Create dir\n",
    "start = time.time()\n",
    "filename = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "print(\"Start: \" + str(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")))\n",
    "\n",
    "dir_name = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "dir_path = '/mnt/PConv-Keras/output_sample/' + dir_name\n",
    "os.makedirs(dir_path)\n",
    "\n",
    "n = 0\n",
    "\n",
    "for (masked, mask), ori in tqdm(test_generator):\n",
    "    masked = cv2.resize(masked[0], (cst.MAX_WIDTH, cst.MAX_HEIGHT))[np.newaxis, ...]\n",
    "    mask = cv2.resize(mask[0], (cst.MAX_WIDTH, cst.MAX_HEIGHT))[np.newaxis, ...]\n",
    "    ori = cv2.resize(ori[0], (cst.MAX_WIDTH, cst.MAX_HEIGHT))[np.newaxis, ...]\n",
    "    \n",
    "    # Run predictions for this batch of images\n",
    "    pred_img = model.predict([masked, mask])\n",
    "    pred_time = datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "            \n",
    "    # Clear current output and display test images\n",
    "    for i in range(len(ori)):\n",
    "        mask_image = Image.fromarray(np.uint8(masked[i,:,:,:]*255))\n",
    "        pred_image = Image.fromarray(np.uint8((pred_img[i,:,:,:]*1.*255)))\n",
    "        ori_image  = Image.fromarray(np.uint8(ori[i,:,:,:]*255))\n",
    "#         print(pred_img)\n",
    "#         print(pred_img.mean())        \n",
    "#         print(np.uint8((pred_img[i,:,:,:]*1.)*255))\n",
    "                \n",
    "        save_mask_path = '/mnt/PConv-Keras/output_sample/{}/{}_masked_img_{}.png'.format(dir_name, pred_time, i)\n",
    "        save_pred_path = '/mnt/PConv-Keras/output_sample/{}/{}_predicted_img_{}.png'.format(dir_name, pred_time, i)\n",
    "        save_ori_path  = '/mnt/PConv-Keras/output_sample/{}/{}_original_img_{}.png'.format(dir_name, pred_time, i)\n",
    "        \n",
    "        mask_image.save(save_mask_path)\n",
    "        pred_image.save(save_pred_path)\n",
    "        ori_image.save(save_ori_path)\n",
    "\n",
    "        n += 1        \n",
    "        \n",
    "    # Only create predictions for about 100 images\n",
    "    if n > 5:\n",
    "        break\n",
    "        \n",
    "        \n",
    "elapsed_time = time.time() - start            \n",
    "print(\"Elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training on PIXNET Food 20. It's only for demo. Please use Command Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_callback(model):\n",
    "    \"\"\"Called at the end of each epoch, displaying our previous test images,\n",
    "    as well as their masked predictions and saving them to disk\"\"\"\n",
    "    \n",
    "    # Get samples & Display them        \n",
    "    pred_img = model.predict([masked, mask])\n",
    "    pred_time = datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "\n",
    "    # Clear current output and display test images\n",
    "    for i in range(len(ori)):\n",
    "        _, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "        axes[0].imshow(masked[i,:,:,:])\n",
    "        axes[1].imshow(pred_img[i,:,:,:] * 1.)\n",
    "        axes[2].imshow(ori[i,:,:,:])\n",
    "        axes[0].set_title('Masked Image')\n",
    "        axes[1].set_title('Predicted Image')\n",
    "        axes[2].set_title('Original Image')\n",
    "                \n",
    "        plt.savefig('{}/data/output_samples/img_{}_{}.png'.format(cst.MNT_PATH, i, pred_time))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1 - with batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "model = PConvUnet(weight_filepath='data/model/')\n",
    "model.load(\"/mnt/PConv-Keras/data/model/3_weights_2018-09-23-17-22-33.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run training for certain amount of epochs\n",
    "model.fit(\n",
    "    train_generator, \n",
    "    steps_per_epoch=10000,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=100,\n",
    "    epochs=50,        \n",
    "    plot_callback=plot_callback,\n",
    "    callbacks=[\n",
    "        TensorBoard(log_dir='../data/logs/initial_training', write_graph=False)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2 - without batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load weights from previous run\n",
    "model = PConvUnet(weight_filepath='data/logs/')\n",
    "model.load(\n",
    "    '{}/data/model/weight-256-512/3000_weights_2018-10-07-05-52-50.h5'.format(cst.MNT_PATH),\n",
    "    train_bn=False,\n",
    "    lr=0.00005\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Run training for certain amount of epochs\n",
    "model.fit(\n",
    "    train_generator, \n",
    "    steps_per_epoch=3,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=100,\n",
    "    epochs=1,        \n",
    "    workers=3,\n",
    "    plot_callback=plot_callback,\n",
    "    callbacks=[\n",
    "        TensorBoard(log_dir='../data', write_graph=False)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Phase 3 - Generating samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Load weights from previous run\n",
    "print(cst.MAX_HEIGHT)\n",
    "print(cst.MAX_WIDTH)\n",
    "\n",
    "model = PConvUnet(\n",
    "    img_rows=cst.MAX_HEIGHT,\n",
    "    img_cols=cst.MAX_WIDTH,\n",
    "    weight_filepath='data/model/')\n",
    "\n",
    "# model = PConvUnet(weight_filepath='data/model/')\n",
    "model.load(\n",
    "    '/mnt/PConv-Keras/data/model/weight-crop-512-1024/1_weights_2018-10-27-05-22-52.h5',\n",
    "    train_bn=False,\n",
    "    lr=0.00005\n",
    ")\n",
    "\n",
    "\n",
    "# model.load(\n",
    "#     '/mnt/PConv-Keras/data/model/weight-256-512/3000_weights_2018-10-07-05-52-50.h5',\n",
    "#     train_bn=False,\n",
    "#     lr=0.00005\n",
    "# )\n",
    "\n",
    "# You need to name weight \"<Num>_weights_<Year>-<Month>-<Day>-<Time>.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Masked, Predicted, Originalの画像をそれぞれ保存 by using PIL\n",
    "from PIL import Image\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Create dir\n",
    "filename = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "print(\"Start: \" + str(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")))\n",
    "\n",
    "dir_name = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "dir_path = '/mnt/PConv-Keras/output_sample/' + dir_name\n",
    "os.makedirs(dir_path)\n",
    "\n",
    "n = 0\n",
    "\n",
    "for (masked, mask), ori in tqdm(test_generator):\n",
    "#     print(mask.shape)\n",
    "    masked = cv2.resize(masked[0], (cst.MAX_WIDTH, cst.MAX_HEIGHT))[np.newaxis, ...]\n",
    "    mask = cv2.resize(mask[0], (cst.MAX_WIDTH, cst.MAX_HEIGHT))[np.newaxis, ...]\n",
    "    ori = cv2.resize(ori[0], (cst.MAX_WIDTH, cst.MAX_HEIGHT))[np.newaxis, ...]\n",
    "    \n",
    "    # Run predictions for this batch of images\n",
    "    pred_img = model.predict([masked, mask])/255\n",
    "    pred_time = datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "            \n",
    "    # Clear current output and display test images\n",
    "    for i in range(len(ori)):\n",
    "        mask_image = Image.fromarray(np.uint8(masked[i,:,:,:]*255))\n",
    "        pred_image = Image.fromarray(np.uint8((pred_img[i,:,:,:] * 1.)*255))\n",
    "        print()\n",
    "        ori_image  = Image.fromarray(np.uint8(ori[i,:,:,:]*255))\n",
    "                \n",
    "        save_mask_path = '/mnt/PConv-Keras/output_sample/{}/{}_masked_img_{}.png'.format(dir_name, pred_time, i)\n",
    "        save_pred_path = '/mnt/PConv-Keras/output_sample/{}/{}_predicted_img_{}.png'.format(dir_name, pred_time, i)\n",
    "        save_ori_path  = '/mnt/PConv-Keras/output_sample/{}/{}_original_img_{}.png'.format(dir_name, pred_time, i)\n",
    "        \n",
    "        mask_image.save(save_mask_path)\n",
    "        pred_image.save(save_pred_path)\n",
    "        ori_image.save(save_ori_path)\n",
    "\n",
    "        n += 1        \n",
    "        \n",
    "    # Only create predictions for about 100 images\n",
    "    if n > 30:\n",
    "        break\n",
    "        \n",
    "        \n",
    "elapsed_time = time.time() - start            \n",
    "print(\"Elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Masked, Predicted, Originalの画像をそれぞれ保存 by using matplotlib\n",
    "n = 0\n",
    "\n",
    "\n",
    "def plot_setting_and_save(save_filename):\n",
    "    axes.tick_params(labelbottom=\"off\",bottom=\"off\") # delete x axes\n",
    "    axes.tick_params(labelleft=\"off\",left=\"off\") # delete y axes        \n",
    "    plt.gca().spines['top'].set_visible(False) # delete axis spines\n",
    "    plt.gca().spines['right'].set_visible(False)\n",
    "    plt.gca().spines['bottom'].set_visible(False)\n",
    "    plt.gca().spines['left'].set_visible(False)        \n",
    "    axes.set_xticklabels([])\n",
    "    \n",
    "    plt.savefig(save_filename, bbox_inches=\"tight\", pad_inches=0)    \n",
    "    plt.close()\n",
    "\n",
    "\n",
    "for (masked, mask), ori in tqdm(test_generator):\n",
    "    \n",
    "    # Run predictions for this batch of images\n",
    "    pred_img = model.predict([masked, mask])\n",
    "    pred_time = datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "    \n",
    "    # Clear current output and display test images\n",
    "    for i in range(len(ori)):\n",
    "        # Save masked image        \n",
    "        _, axes = plt.subplots()\n",
    "        axes.imshow(masked[i,:,:,:])        \n",
    "        save_filename = '{}/data/output_samples/masked_img_{}_{}.png'.format(cst.MNT_PATH, i, pred_time)\n",
    "        plot_setting_and_save(save_filename)\n",
    "        \n",
    "        # Save predicted image\n",
    "        _, axes = plt.subplots()\n",
    "        axes.imshow(pred_img[i,:,:,:] * 1.)\n",
    "        save_filename = '{}/data/output_samples/predicted_img_{}_{}.png'.format(cst.MNT_PATH, i, pred_time)\n",
    "        plot_setting_and_save(save_filename)\n",
    "        \n",
    "        # Save original image\n",
    "        _, axes = plt.subplots()\n",
    "        axes.imshow(ori[i,:,:,:])\n",
    "        save_filename = '{}/data/output_samples/original_img_{}_{}.png'.format(cst.MNT_PATH, i, pred_time)\n",
    "        plot_setting_and_save(save_filename)\n",
    "        \n",
    "        # plt.show()\n",
    "        n += 1\n",
    "        \n",
    "    # Only create predictions for about 100 images\n",
    "    if n > 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask, Predicted Original を1枚の画像に保存\n",
    "n = 0\n",
    "for (masked, mask), ori in tqdm(test_generator):\n",
    "    \n",
    "    # Run predictions for this batch of images\n",
    "    pred_img = model.predict([masked, mask])\n",
    "    pred_time = datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "    \n",
    "    # Clear current output and display test images\n",
    "    for i in range(len(ori)):\n",
    "        _, axes = plt.subplots(1, 3, figsize=(30, 5))\n",
    "        axes[0].imshow(masked[i,:,:,:])\n",
    "        axes[1].imshow(pred_img[i,:,:,:] * 1.)\n",
    "        axes[2].imshow(ori[i,:,:,:])\n",
    "        axes[0].set_title('Masked Image')\n",
    "        axes[1].set_title('Predicted Image')\n",
    "        axes[2].set_title('Original Image')\n",
    "        \n",
    "        axes[0].xaxis.set_major_formatter(NullFormatter())\n",
    "        axes[0].yaxis.set_major_formatter(NullFormatter())\n",
    "        axes[1].xaxis.set_major_formatter(NullFormatter())\n",
    "        axes[1].yaxis.set_major_formatter(NullFormatter())\n",
    "        axes[2].xaxis.set_major_formatter(NullFormatter())\n",
    "        axes[2].yaxis.set_major_formatter(NullFormatter())\n",
    "                \n",
    "        plt.savefig('{}/data/output_samples/img_{}_{}.png'.format(cst.MNT_PATH, i, pred_time))\n",
    "        plt.close()\n",
    "        n += 1        \n",
    "        \n",
    "    # Only create predictions for about 100 images\n",
    "    if n > 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 任意のマスク画像を用いて画像生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load weights from previous run\n",
    "# Need to name weight \"<Num>_weights_<Year>-<Month>-<Day>-<Time>.h5\n",
    "\n",
    "# 256x512\n",
    "# /mnt/PConv-Keras/data/model/weight-resize-1536x3072/weight-256x512/19_weights_2018-11-01-10-10-40.h5\n",
    "\n",
    "# 256x512\n",
    "# /mnt/PConv-Keras/data/model/weight-resize-1536x3072/weight-crop-256x512v2/19_weights_2018-11-09-06-34-40.h5\n",
    "\n",
    "# 512x512 mask -> crop\n",
    "# /mnt/PConv-Keras/data/model/weight-resize-1536x3072/weight-crop-512x512/15_weights_2018-11-05-09-45-58.h5\n",
    "\n",
    "# 512x512 crop -> mask\n",
    "# /mnt/PConv-Keras/data/model/weight-resize-1536x3072/weight-crop-512x512v2/20_weights_2018-11-07-14-33-30.h5\n",
    "\n",
    "model = PConvUnet(weight_filepath='data/model/')\n",
    "model.load(\n",
    "    '/mnt/PConv-Keras/data/model/weight-resize-1536x3072/weight-crop-256x512v2/19_weights_2018-11-09-06-34-40.h5',\n",
    "    train_bn=False,\n",
    "    lr=0.00005\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# masked = cv2.imread('/mnt/PConv-Keras/sample_images/blackmask_1536x3072.png')\n",
    "masked = cv2.imread('/mnt/PConv-Keras/sample_images/mask_1536x3072.png')\n",
    "ori    = cv2.imread('/mnt/PConv-Keras/sample_images/ori_1536x3072.png')\n",
    "\n",
    "# # Resize for test(256x512)\n",
    "# masked = cv2.resize(masked, (512, 256))\n",
    "# ori    = cv2.resize(ori, (512, 256))\n",
    "    \n",
    "# cv2.imwrite(\"/nfs/host/PConv-Keras/sample_images/masked.jpg\", masked)\n",
    "# cv2.imwrite(\"/nfs/host/PConv-Keras/sample_images/ori.jpg\", ori)\n",
    "\n",
    "masked = cv2.cvtColor(masked, cv2.COLOR_BGR2RGB) # 青みがかってしまうのでRGBに変更\n",
    "ori    = cv2.cvtColor(ori, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "img_diff = cv2.absdiff(ori, masked)\n",
    "mask = cv2.threshold(img_diff, 5, 255, cv2.THRESH_BINARY_INV)[1] # 2値化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4階テンソルにして、0〜1の間に値を収める(こうしないと真っ黒なpredicted画像が出力される)\n",
    "mask   = mask[np.newaxis, ...]/255   # mask.reshape((1, 256, 512, 3))\n",
    "masked = masked[np.newaxis, ...]/255 # masked.reshape((1, 256, 512, 3))\n",
    "\n",
    "# cv2.imwrite(\"/nfs/host/PConv-Keras/sample_images/mask_256_512.jpg\", mask[0]) # 3階のテンソルにする\n",
    "# cv2.imwrite(\"/nfs/host/PConv-Keras/sample_images/masked_256_512.jpg\", masked[0]) # 3階のテンソルにする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 標準的な推論方法\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "\n",
    "pred_img = model.predict([masked, mask])\n",
    "pred_time = datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "\n",
    "pred_image = Image.fromarray(np.uint8((pred_img[0,:,:,:] * 1.)*255))\n",
    "save_pred_path = '/mnt/PConv-Keras/sample_images/predicted_image_black.jpg'.format(pred_time)\n",
    "pred_image.save(save_pred_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# マスク部分を囲む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_mask_pixel(mask):\n",
    "#     height, width = mask.shape[0], mask.shape[1]\n",
    "#     masked_pixels = []\n",
    "#     for y in range(height):\n",
    "#         for x in range(width):\n",
    "#             if mask[y, x, 0] == 1: # 1: white\n",
    "#                 masked_pixels.append(1)\n",
    "#             else: # 0: black\n",
    "#                 masked_pixels.append(0)                \n",
    "#     print(len(masked_pixels))\n",
    "#     return masked_pixels\n",
    "\n",
    "# 1536*3072= 4718592"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(ImageDataGenerator):\n",
    "    def flow_from_directory(self, directory, *args, **kwargs):\n",
    "        generator = super().flow_from_directory(directory, class_mode=None, *args, **kwargs)\n",
    "        while True:\n",
    "            \n",
    "            # Get augmented image samples\n",
    "            ori = next(generator)\n",
    "\n",
    "            # Get masks for each image sample\n",
    "            mask = np.stack([random_mask(ori.shape[1], ori.shape[2]) for _ in range(ori.shape[0])], axis=0)\n",
    "\n",
    "            # Apply masks to all image sample\n",
    "            masked = deepcopy(ori)\n",
    "            masked[mask==0] = 1\n",
    "            \n",
    "            print(ori.shape)\n",
    "            print(mask.shape)\n",
    "            \n",
    "\n",
    "            # Yield ([ori, masl],  ori) training batches\n",
    "            # print(masked.shape, ori.shape)\n",
    "            gc.collect()\n",
    "            yield [masked, mask], ori\n",
    "\n",
    "            \n",
    "# Create testing generator\n",
    "test_datagen = DataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    cst.TEST_PATH,\n",
    "    target_size=(32, 32),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=1\n",
    ")\n",
    "\n",
    "# cst.MAX_HEIGHT, cst.MAX_WIDTH\n",
    "# 20, 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 32, 32, 3)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got inputs shapes: [(None, 1, 1, 256), (None, 2, 2, 256)]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-ce819b343e1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPConvUnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_filepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'data/model/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m model.load(\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m'/mnt/PConv-Keras/data/model/weight-resize-1536x3072/weight-crop-256x512v2/19_weights_2018-11-09-06-34-40.h5'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtrain_bn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.00005\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/PConv-Keras/libs/pconv_model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, img_rows, img_cols, weight_filepath)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# Create UNet-like model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_pconv_unet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/PConv-Keras/libs/pconv_model.py\u001b[0m in \u001b[0;36mbuild_pconv_unet\u001b[0;34m(self, train_bn, lr)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0md_conv9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_mask9\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me_conv8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_mask8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_conv7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_mask7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 256\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0md_conv10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_mask10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_conv9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_mask9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_conv6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_mask6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 256\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0md_conv11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_mask11\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_conv10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_mask10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_conv5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_mask5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 256\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/PConv-Keras/libs/pconv_model.py\u001b[0m in \u001b[0;36mdecoder_layer\u001b[0;34m(img_in, mask_in, e_conv, e_mask, filters, kernel_size, bn)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mup_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUpSampling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0mup_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUpSampling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0mconcat_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me_conv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mup_img\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m             \u001b[0mconcat_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mup_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0mconv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconcat_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcat_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Pconv-Keras/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    429\u001b[0m                                          \u001b[0;34m'You can build it manually via: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m                                          '`layer.build(batch_input_shape)`')\n\u001b[0;32m--> 431\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Pconv-Keras/lib/python3.6/site-packages/keras/layers/merge.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    360\u001b[0m                              \u001b[0;34m'inputs with matching shapes '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m                              \u001b[0;34m'except for the concat axis. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m                              'Got inputs shapes: %s' % (input_shape))\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_merge_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got inputs shapes: [(None, 1, 1, 256), (None, 2, 2, 256)]"
     ]
    }
   ],
   "source": [
    "model = PConvUnet(weight_filepath='data/model/')\n",
    "model.load(\n",
    "    '/mnt/PConv-Keras/data/model/weight-resize-1536x3072/weight-crop-256x512v2/19_weights_2018-11-09-06-34-40.h5',\n",
    "    train_bn=False,\n",
    "    lr=0.00005\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# マスク部分の周辺から中心に向けて推論する\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def plot_contours(axes, img, contours):\n",
    "    from matplotlib.patches import Polygon\n",
    "    axes.imshow(img)\n",
    "    axes.axis('off')\n",
    "    for i, cnt in enumerate(contours):\n",
    "        cnt = np.squeeze(cnt)             \n",
    "        axes.add_patch(Polygon(cnt, fill=None, lw=1., color='r')) # 点同士を結ぶ線を描画        \n",
    "        axes.text(cnt[0][0], cnt[0][1], i, color='orange', size='20') # 輪郭の番号を描画\n",
    "        \n",
    "\n",
    "def draw_contours(axes, img, contours):\n",
    "    from matplotlib.patches import Polygon\n",
    "    axes.imshow(img)\n",
    "    axes.axis('off')\n",
    "    for i, cnt in enumerate(contours):\n",
    "        x,y,w,h = cv2.boundingRect(cnt)\n",
    "        img = cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)        \n",
    "        print(str(i) + \": \" + str(x) + \", \" + str(y) + \", \" + str(w) + \", \" + str(h))\n",
    "                    \n",
    "    cv2.imwrite(\"/mnt/PConv-Keras/sample_images/\" + str(i) + '.jpg', img)\n",
    "\n",
    "    \n",
    "def recursive_predict(masked, mask, contours):\n",
    "    edge = 20\n",
    "    stride = 10\n",
    "        \n",
    "    for i, cnt in enumerate(contours):\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        \n",
    "        loop_x = int(w/stride) + 1\n",
    "        loop_y = int(h/stride) + 1        \n",
    "        print(\"loop_x:\" + str(loop_x) + \", loop_y:\" + str(loop_y))\n",
    "        \n",
    "        for i in range(loop_x):        \n",
    "            for j in range(loop_y): \n",
    "                print(str(i) + \" - \" + str(j))\n",
    "                print(\"x:\" + str(x) + \", y:\" + str(y))\n",
    "                \n",
    "                upper_left_x = x - int(edge/2)\n",
    "                upper_left_y = y - int(edge/2)\n",
    "                bottom_right_x = x + int(edge/2)\n",
    "                bottom_right_y = y + int(edge/2)\n",
    "                \n",
    "                croped_masked = masked[:, upper_left_y:bottom_right_y, upper_left_x:bottom_right_x]\n",
    "                croped_mask = mask[:, upper_left_y:bottom_right_y, upper_left_x:bottom_right_x]\n",
    "                print(croped_masked.shape)\n",
    "                \n",
    "                # You need to use image size of at least 256x256\n",
    "                croped_pred = model.predict([croped_masked, croped_mask])\n",
    "                \n",
    "                masked[upper_left_y:bottom_right_y, upper_left_x:bottom_right_x] = croped_pred # Overlay for update image\n",
    "                \n",
    "                x += stride\n",
    "                y += stride       \n",
    "                \n",
    "    recursive_predict_masked = Image.fromarray(np.uint8(masked[i,:,:,:]*255))                \n",
    "    recursive_predict_masked.save('/mnt/PConv-Keras/sample_images/recursive_predict_masked.png')\n",
    "\n",
    "\n",
    "\n",
    "# Read image\n",
    "ori    = cv2.imread('/mnt/PConv-Keras/sample_images/ori_1536x3072.png')\n",
    "masked = cv2.imread('/mnt/PConv-Keras/sample_images/mask_1536x3072.png')\n",
    "\n",
    "# 青みがかってしまうのでRGBに変更\n",
    "masked = cv2.cvtColor(masked, cv2.COLOR_BGR2RGB) \n",
    "ori    = cv2.cvtColor(ori, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Create mask image\n",
    "img_diff = cv2.absdiff(ori, masked)\n",
    "mask = cv2.threshold(img_diff, 5, 255, cv2.THRESH_BINARY_INV)[1] # Binarization\n",
    "\n",
    "# Get contours\n",
    "img_diff = cv2.cvtColor(img_diff, cv2.COLOR_BGR2GRAY) # Convert to CV_8UC1\n",
    "gray_mask = cv2.threshold(img_diff, 5, 255, cv2.THRESH_BINARY_INV)[1] # Binarization for findContours\n",
    "_, contours, _ = cv2.findContours(gray_mask, 1, 2)\n",
    "\n",
    "mask   = mask[np.newaxis, ...]/255   # mask.reshape((1, 256, 512, 3))\n",
    "masked = masked[np.newaxis, ...]/255 \n",
    "\n",
    "\n",
    "print(len(contours))\n",
    "print(mask.shape)\n",
    "\n",
    "print('---------------')\n",
    "recursive_predict(masked, mask, contours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Show and Save image\n",
    "# \n",
    "\n",
    "\n",
    "# _, axes = plt.subplots(1, 1, figsize=(20, 5))\n",
    "# axes.imshow(mask)\n",
    "# plt.show()\n",
    "# save_ori = Image.fromarray(masked)\n",
    "# save_ori.save(\"/mnt/PConv-Keras/sample_images/save.jpg\")\n",
    "\n",
    "\n",
    "# Show mask image\n",
    "# fig, axes = plt.subplots(figsize=(10, 10))\n",
    "# axes.imshow(mask)\n",
    "# axes.axis('off')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# Show boxed mask image\n",
    "fig, axes = plt.subplots(figsize=(10, 10))\n",
    "plot_contours(axes, gray_mask, contours)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Save image\n",
    "draw_contours(axes, mask, contours)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PConv-Keras",
   "language": "python",
   "name": "pytorch-segmentation-detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
